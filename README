# Projet de Scoring Crédit - "Prêt à dépenser"

Implémentation d'un modèle de scoring crédit avec déploiement MLOps complet pour l'entreprise fictive "Prêt à dépenser".

## Contexte du projet

Ce projet s'inscrit dans le cadre d'une formation en Data Science. L'objectif est de développer un outil de scoring crédit qui calcule la probabilité qu'un client rembourse son crédit, puis classifie la demande en crédit accordé ou refusé.

## Objectifs

- Construire un modèle de scoring automatisé pour prédire la probabilité de défaut de paiement
- Analyser l'importance des variables (globale et locale) pour assurer la transparence
- Déployer le modèle via une API REST sur le cloud
- Mettre en œuvre une approche MLOps complète avec tracking des expérimentations
- Surveiller la dérive des données en production

## Structure du projet

```
credit-scoring-project/
├── notebooks/
│   ├── 01_data_exploration.ipynb
│   ├── 02_feature_engineering.ipynb
│   └── 03_model_training.ipynb
├── api/
│   └── app_production.py
├── tests/
│   └── test_api.py
├── models/
│   ├── lightgbm_final_model_optimized.pkl
│   └── optimal_threshold_optimized.pkl
├── data/
│   ├── source/
│   └── processed/
├── streamlit_app.py
├── requirements.txt
├── Procfile
└── README.md
```

## Technologies utilisées

### Machine Learning
- **Python 3.11** - Langage principal
- **Pandas & NumPy** - Manipulation des données
- **Scikit-learn** - Preprocessing et métriques
- **LightGBM** - Modèle de classification
- **SHAP** - Explicabilité du modèle

### MLOps et déploiement
- **MLflow** - Tracking des expérimentations et registry des modèles
- **Flask** - API REST
- **Gunicorn** - Serveur de production
- **Railway** - Déploiement cloud de l'API
- **Streamlit** - Interface de test

### CI/CD et tests
- **Git & GitHub** - Versioning du code
- **GitHub Actions** - Pipeline CI/CD
- **Pytest** - Tests unitaires
- **Evidently** - Monitoring de la dérive des données

## Installation et configuration

### Prérequis
- Python 3.11+
- Git

### Installation locale

1. Cloner le repository
```bash
git clone https://github.com/votre-username/credit-scoring-project.git
cd credit-scoring-project
```

2. Créer un environnement virtuel
```bash
conda create -n credit-scoring python=3.11
conda activate credit-scoring
```

3. Installer les dépendances
```bash
pip install -r requirements.txt
```

4. Configurer MLflow (optionnel pour développement)
```bash
mlflow server --host 0.0.0.0 --port 5000
```

### Test de l'API en local

```bash
cd api
python app_production.py
```

L'API sera accessible sur `http://localhost:5001`

### Endpoints disponibles

- `GET /health` - Vérification du statut de l'API
- `POST /predict` - Prédiction du risque de crédit
- `GET /` - Documentation de l'API

## Utilisation

### API de prédiction

Endpoint : `POST /predict`

Format de la requête :
```json
{
    "EXT_SOURCE_2": 0.78,
    "EXT_SOURCE_3": 0.688,
    "CODE_GENDER": 0,
    "DAYS_EMPLOYED": -3000,
    ...
}
```

Réponse :
```json
{
    "probability": 0.052,
    "decision": "ACCORDE",
    "threshold": 0.0991,
    "top_features": [...]
}
```

### Interface Streamlit

L'interface web permet de tester l'API de deux manières :
1. **Saisie manuelle** des variables principales
2. **Sélection par identifiant** client depuis l'échantillon de données

Accès : [Lien vers l'interface Streamlit](votre-lien-streamlit)

## Modélisation

### Données
- **Source** : Kaggle Home Credit Default Risk
- **Volume** : 307,511 lignes d'entraînement
- **Features** : 234 variables après feature engineering
- **Cible** : Variable binaire (0=remboursé, 1=défaut)

### Modèle retenu
- **Algorithme** : LightGBM Classifier
- **Optimisation** : RandomizedSearchCV avec score métier personnalisé
- **Seuil optimal** : 0.0991 (optimisé selon le coût métier)
- **Performance** : AUC = 0.794, Recall = 66.0%

### Score métier
Le modèle optimise un score métier qui tient compte du déséquilibre des coûts :
- **Faux négatif (FN)** : Coût = 10€ (mauvais client accepté)
- **Faux positif (FP)** : Coût = 1€ (bon client refusé)

### Variables importantes
Les principales variables influençant la décision :
1. **EXT_SOURCE_2** (12.2% d'importance)
2. **EXT_SOURCE_3** (12.0% d'importance)
3. **EXT_SOURCE_1** (5.5% d'importance)
4. **DAYS_EMPLOYED** (3.9% d'importance)
5. **CODE_GENDER** (3.6% d'importance)

## Tests

Exécution des tests unitaires :
```bash
pytest tests/test_api.py -v
```

Les tests couvrent :
- Fonctionnement des endpoints
- Structure des réponses API
- Cohérence de la logique métier
- Gestion des erreurs
- Reproductibilité des prédictions

## Déploiement

### API (Railway)
L'API est déployée automatiquement sur Railway via GitHub Actions.

URL de production : `https://api-credit-scoring-production.up.railway.app`

### Interface (Streamlit Cloud)
L'interface utilisateur est hébergée sur Streamlit Cloud.

### Pipeline CI/CD
Chaque push sur la branche main déclenche :
1. Tests unitaires automatiques
2. Vérification de la structure du projet
3. Validation du modèle
4. Déploiement automatique

## Monitoring

### Surveillance de la dérive
- **Outil** : Evidently
- **Méthode** : Comparaison entre données d'entraînement et production
- **Rapport** : Génération automatique d'un tableau HTML d'analyse

### MLflow Tracking
- **Expérimentations** : Toutes les expériences sont trackées
- **Modèles** : Registry centralisé des versions
- **Métriques** : Suivi des performances et hyperparamètres

## Contributeur

**Brice Béchet**
- Formation : Master 2 Data Scientist - OpenClassrooms
- Projet réalisé en juin 2025


## Licence

Projet réalisé dans un cadre pédagogique - OpenClassrooms